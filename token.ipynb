{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "18452M8MGYCOaGn-PD5A1GnHtodf-R53d",
      "authorship_tag": "ABX9TyNgNvYvXgvcJxgkxDSWKywq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepshabd/AppInstall/blob/master/token.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxQZgmMw2u3S",
        "outputId": "ed0af7b8-0597-46a3-b331-80a2b101c7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 26491), ('of', 13084), ('to', 11292), ('a', 10526), ('and', 9623), ('in', 8741), ('that', 5943), ('for', 4121), ('said', 3832), ('is', 3769)]\n"
          ]
        }
      ],
      "source": [
        "# tokenizer.py\n",
        "\n",
        "import re\n",
        "# ðŸ‘‡ï¸ for Anaconda\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "# ðŸ‘‡ï¸ for Anaconda\n",
        "#conda install -c conda-forge spacy\n",
        "#python -m spacy download en_core_web_sm\n",
        "#python -m spacy download en\n",
        "\n",
        "# Tokenizes a string. Takes a string (a sentence), splits out punctuation and contractions, and returns a list of\n",
        "# strings, with each string being a token.\n",
        "\n",
        "def readFileAndToeknize():\n",
        "    wordCounter = {}\n",
        "\n",
        "    string = readFile()\n",
        "    stringArray = word_tokenize(string)\n",
        "    for word in stringArray:\n",
        "        if(word.isalpha()):\n",
        "            if(word in  wordCounter):\n",
        "                wordCounter[word] += 1\n",
        "            else:\n",
        "                wordCounter[word] = 1\n",
        "\n",
        "    #sortedByCount = sorted(wordCounter.items(),key=lambda x:x[1],)\n",
        "    sortedByCount = sorted(wordCounter.items(),key=lambda x:x[1],reverse=True)\n",
        "    print(sortedByCount[:10])\n",
        "\n",
        "\"\"\"     for key in  wordCounter:\n",
        "        if(wordCounter[key] >5):\n",
        "            print(key+\":\"+str(wordCounter[key]))\n",
        "     \"\"\"\n",
        "\n",
        "\n",
        "def readFile():\n",
        "    f = open(\"/content/sample_data/nyt.txt\", \"r\")\n",
        "    string = f.read()\n",
        "    f.close()\n",
        "    return string\n",
        "\n",
        "def tokenize(string):\n",
        "    # print(repr(string))\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),.!?\\'`\\-\\\"]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\"\\.\", \" . \", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\?\", \" ? \", string)\n",
        "    string = re.sub(r\"\\(\", \" ( \", string)\n",
        "    string = re.sub(r\"\\)\", \" ) \", string)\n",
        "    string = re.sub(r\"\\-\", \" - \", string)\n",
        "    string = re.sub(r\"\\\"\", \" \\\" \", string)\n",
        "    # We may have introduced double spaces, so collapse these down\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return list(filter(lambda x: len(x) > 0, string.split(\" \")))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "   readFileAndToeknize()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "o3848gJo4AHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Oiu1m7Mv23q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "0LmfEwHC28sO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "0gNZcUhN29UZ"
      }
    }
  ]
}